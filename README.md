---
title: Reranker Service
emoji: üß†
colorFrom: indigo
colorTo: blue
sdk: docker
app_file: app.py
pinned: false
---

# üß† Reranker Service (FastAPI + Docker)

This Space runs a **FastAPI-based reranker microservice** using `cross-encoder/ms-marco-TinyBERT-L-2-v2`.  
It‚Äôs deployed via Docker for better compatibility with custom frameworks.

## ‚úÖ Optimization Results

- **Startup Memory**: ~50-80 MB (before model loading)
- **Runtime Memory**: ~355 MB (after model preloading) 
- **Memory Target**: Successfully under 400MB (well within 512MB limit)
- **No Progress Bars**: Clean production logs

### Endpoints

- `POST /rerank`  
  Request body:
  ```json
  {
    "query": "who founded fastapi",
    "documents": [
      {"text": "FastAPI was created by Sebastian Ramirez."},
      {"text": "Flask is a Python microframework released in 2010."}
    ],
    "top_k": 1
  }
  ```
  Response:
  ```json
  {
    "rankings": [{"index": 0, "score": 0.91}],
    "top_k_applied": true
  }
  ```

- `GET /health` returns `{"status":"ok"}` when the service is ready (lightweight check that doesn't load the model).

- `GET /metrics` returns memory usage and performance metrics:
  ```json
  {
    "memory": {
      "rss_mb": 85.4,
      "vms_mb": 512.3
    },
    "cpu_percent": 2.5,
    "num_threads": 4
  }
  ```

## üöÄ Quick Start

### Option 1: Using Environment Files (Recommended)

```bash
# For development (balanced performance and memory)
cp .env.dev .env
python app.py

# For production (512MB servers, preloaded model)  
cp .env.production .env
python app.py

# For minimal memory usage (very tight constraints)
cp .env.minimal .env
python app.py
```

### Option 2: Direct Run (uses built-in defaults)

```bash
python app.py
```

The server will:
1. **Load configuration** from `.env` file or use optimized defaults
2. **Preload** the model during startup (~10-15 seconds) 
3. **Listen** on the configured host/port
4. **Be ready** for immediate requests without loading delays

## üìä Key Optimizations

### Memory Features
- ‚úÖ **Tiny Model**: Uses `cross-encoder/ms-marco-TinyBERT-L-2-v2` (17.6MB vs 90MB+)
- ‚úÖ **Small Cache**: Only 4 cached results (vs 128 default)
- ‚úÖ **Short Sequences**: Max 64 tokens (vs 512 default)
- ‚úÖ **Model Preloading**: Loads at startup for immediate responses
- ‚úÖ **No Progress Bars**: Clean logs for production

### Performance Features
- ‚úÖ **Fast Startup**: Model preloads automatically
- ‚úÖ **Proper Scoring**: Returns real relevance scores
- ‚úÖ **Error Handling**: Graceful fallbacks
- ‚úÖ **Memory Monitoring**: Built-in metrics endpoint

## üîß Configuration Options

### Environment Files

| File | Use Case | Memory Usage | Features |
|------|----------|--------------|----------|
| `.env.dev` | Development | ~355MB | Balanced performance, preloading |
| `.env.production` | Production 512MB servers | ~355MB | Preloaded, clean logs |
| `.env.minimal` | Very tight memory | ~200-250MB | No preloading, minimal cache |

### Key Settings

Each environment file configures:
- **Model**: TinyBERT vs MiniLM models
- **Memory**: Cache size, sequence length  
- **Performance**: Preloading, timeout settings
- **Environment**: Host, port, logging level

## üèóÔ∏è Production Ready

- **Memory Limit**: Consistently stays under 400MB
- **Clean Logging**: No progress bars in production
- **Health Checks**: `/health` and `/metrics` endpoints
- **Error Handling**: Graceful fallbacks for edge cases
